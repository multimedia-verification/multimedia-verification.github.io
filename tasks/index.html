<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Grand Challenge on Multimedia Verification">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ACMMM25-Grand Challenge on Multimedia Verification</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="../static/css/bulma.min.css">
  <link rel="stylesheet" href="../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="../static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="../static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="../static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="../static/js/fontawesome.all.min.js"></script>
  <script src="../static/js/bulma-carousel.min.js"></script>
  <script src="../static/js/bulma-slider.min.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navbar-menu">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>

    <div id="navbar-menu" class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="/">
            <span class="icon">
                <i class="fas fa-home"></i>
            </span>
            </a>
            <a class="navbar-item" href="/tasks">
            <div>Task Description</div>
            </a>
            <a class="navbar-item" href="/submission">
            <div>Submission Guidelines</div>
            </a>
            <a class="navbar-item" href="/evaluation">
            <div>Evaluation Criteria</div>
            </a>
					  <a class="navbar-item" href="/program">
			<div>Program</div>
			</a>
            <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link">Challenge iteration</a>
            <div class="navbar-dropdown">
      				<a class="navbar-item" href="https://detecting-cheapfakes.github.io/icmr-2024.html">
      				ACM ICMR 2024
      				</a>
      				<a class="navbar-item" href="https://detecting-cheapfakes.github.io/icme-2023.html">
      				IEEE ICME 2023
      				</a>
      				<a class="navbar-item" href="https://detecting-cheapfakes.github.io/acmmm-2022.html">
      				ACMMM 2022
      				</a>
      				<a class="navbar-item" href="https://2021.acmmmsys.org/cheapfake_challenge.php">
      				MMSys 2021
      				</a>
      			</div>
            </div>
        </div>
    </div>
</nav>

<script>
    document.addEventListener('DOMContentLoaded', () => {
        const burger = document.querySelector('.navbar-burger');
        const menu = document.getElementById('navbar-menu');

        if (burger && menu) {
        burger.addEventListener('click', () => {
            burger.classList.toggle('is-active');
            menu.classList.toggle('is-active');
        });
        }
    });
</script>
    

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ACMMM25 - Grand Challenge on Multimedia Verification</h1>
<!--           <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www4.uib.no/en/find-employees/Duc.Tien.Dang.Nguyen">Duc-Tien Dang-Nguyen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Morten Langfeldt Dahlback</a><sup>2</sup>,</span>
            <span class="author-block">
              <a>Minh-Son Dao</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://pakkunandy.github.io/">Anh-Duy Tran</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://sohailahmedkhan.github.io/">Sohail Khan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Kha-Luan Pham</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a >Michael Riegler</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a >Pål Halvorsen</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a>Marc Gallofre Ocana</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Henrik B. Vold</a><sup>7</sup>,
            </span>
            <span class="author-block">
              <a>Silje Førsund</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Minh-Triet Tran</a><sup>8</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Bergen</span>
            <span class="author-block"><sup>2</sup>Faktisk.no</span>
            <span class="author-block"><sup>3</sup>NICT</span>
            <span class="author-block"><sup>4</sup>KU Leuven</span>
            <span class="author-block"><sup>5</sup>Aalto University</span>
            <span class="author-block"><sup>6</sup>Simula Research Laboratory</span>
            <span class="author-block"><sup>7</sup>Institutt for Journalistikk</span>
            <span class="author-block"><sup>8</sup>University of Science - VNUHCM</span>
          </div> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www4.uib.no/en/find-employees/Duc.Tien.Dang.Nguyen">Duc-Tien Dang-Nguyen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Morten Langfeldt Dahlback</a><sup>2</sup>,</span>
<!--             <span class="author-block">
              <a>Minh-Son Dao</a><sup>3</sup>,
            </span> -->
<!--             <span class="author-block">
              <a href="https://pakkunandy.github.io/">Anh-Duy Tran</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://sohailahmedkhan.github.io/">Sohail Khan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Kha-Luan Pham</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a >Michael Riegler</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a >Pål Halvorsen</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a>Marc Gallofre Ocana</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Henrik B. Vold</a><sup>7</sup>,
            </span>
            <span class="author-block">
              <a>Silje Førsund</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Minh-Triet Tran</a><sup>8</sup>,
            </span> -->
		  	<span class="author-block">
              <a href="https://pakkunandy.github.io/">Anh-Duy Tran</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sohailahmedkhan.github.io/">Sohail Khan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Kha-Luan Pham</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a >Michael Riegler</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a >Pål Halvorsen</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a>Marc Gallofre Ocana</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Henrik B. Vold</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a>Silje Førsund</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Minh-Triet Tran</a><sup>7</sup>,
            </span>
          </div>
		          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Bergen</span>
            <span class="author-block"><sup>2</sup>Faktisk.no</span>
<!--             <span class="author-block"><sup>3</sup>NICT</span> -->
<!--             <span class="author-block"><sup>4</sup>KU Leuven</span>
            <span class="author-block"><sup>5</sup>Aalto University</span>
            <span class="author-block"><sup>6</sup>Simula Research Laboratory</span>
            <span class="author-block"><sup>7</sup>Institutt for Journalistikk</span>
            <span class="author-block"><sup>8</sup>University of Science - VNUHCM</span> -->
			            <span class="author-block"><sup>3</sup>KU Leuven</span>
            <span class="author-block"><sup>4</sup>Aalto University</span>
            <span class="author-block"><sup>5</sup>Simula Research Laboratory</span>
            <span class="author-block"><sup>6</sup>Institutt for Journalistikk</span>
            <span class="author-block"><sup>7</sup>University of Science - VNUHCM</span>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://docs.google.com/forms/d/e/1FAIpQLScsz41_qac-a9tImXJuBT4bvY9KN2nR6DvAEHSyQOaZnXW_qg/viewform?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa-solid fa-user-plus"></i>
                  </span>
                  <span>Registration</span>
                  </a>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/multimedia-verification/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa-brands fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <!-- Video Link. -->
<!--               <span class="link-block">
                <a href="https://groups.google.com/g/multimedia-verification"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa-solid fa-users-line"></i>
                  </span>
                  <span>Google group</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop is-centered">
    <div class="content">
      <h2 class="title is-3">Main Task</h2>
      <h3 class="title is-4">Task Description </h3>
      <p><strong>Objective:</strong> Verify the authenticity and context of multimedia content, <strong>which may be in a language other than English</strong>, and provide both a detailed report for fact-checkers and a concise summary for general readers. The languages of the content might not be in English.</p>

      <p><strong>Input:</strong> Each case/task will provide (in a zip file):</p>
      <ul>
          <li><strong>Multimedia Content:</strong> Image(s) or video(s)</li>
          <li><strong>Associated Context:</strong> Captions, descriptions, social media posts, news articles, metadata (if available)</li>
          <li><strong>Additional Clues:</strong> Possible sources, claims, or fact-checker notes (if relevant)</li>
      </ul>
      
      <p><strong>Output:</strong> A verification report (as a text file) <strong>in English</strong>. The report should include the following key information:</p>
      
      <ul>
          <li><strong>Summary of Key Points:</strong> Provide a concise overview of the content, including relevant details. Clearly highlight any uncertainties and underline what is not yet known.</li>
          <li><strong>Content Category:</strong> Assign relevant tags based on platforms, people, brands, or specific topics.</li>
          <li><strong>Forensic Analysis Results:</strong>
              <ul>
                  <li><strong>Authenticity:</strong> Determine if the content is synthetic, modified, or recaptured.</li>
                  <li><strong>Tools &amp; Methods Used:</strong> Specify the verification tools and techniques applied.</li>
                  <li><strong>Synthetic Type (if applicable):</strong> Identify whether it was generated using GANs, Stable Diffusion, or other AI models.</li>
                  <li><strong>Other Artifacts:</strong> Note any detected anomalies or manipulations.</li>
              </ul>
          </li>
          <li><strong>Verified Evidence:</strong> State what can be confirmed about the video/photo based on available evidence.
              <ul>
                  <li><strong>Source Details:</strong> Where the content comes from (URLs, original posts, etc.)</li>
                  <li><strong>Where?</strong> (Location)</li>
                  <li><strong>When?</strong> (Time)</li>
                  <li><strong>Who?</strong> (People, organizations, entities involved)</li>
                  <li><strong>Why?</strong> (Possible motivations or intent)</li>
              </ul>
          </li>
          <li><strong>Other Evidence &amp; Findings:</strong> Any additional relevant information, supporting materials, or external sources</li>
      </ul>
      
      <p><strong>Note:</strong> For each evidence finding, specify the failure type if verification fails: <em>Indeterminate</em> (insufficient or ambiguous data), <em>Inconclusive</em> (attempted but no definitive result), or <em>Not Feasible</em> (limited expertise or tools).</p>
      
      
      <h3 class="title is-4">Sample Dataset </h3>
      <p>You can find the sample dataset <a href="https://github.com/multimedia-verification/multimedia-verification.github.io/blob/faae3051a5b3210312c4694887f7d116f26977a0/dataset/ID212.zip">here</a> </p>
      <p> <strong> The Main Task dataset may contain sensitive or potentially disturbing content, as it reflects real-world events and includes verification reports from fact-checking organizations. Participants are advised to exercise caution when viewing these media files. </strong></p>
      
      <h3 class="title is-4">Competition Stages </h3>
      
      <ul>
          <li><strong>Stage 1 - Training (March - April)</strong>
              <ul>
                  <li>Organizers provide <s>100</s> 50 known cases with input and expected outputs.</li>
                  <li>Participants register, explore tasks, and practice verification.</li>
              </ul>
          </li>
      
          <li><strong>Stage 2 - Validation (May)</strong>
              <ul>
                  <li>Organizers release <s>20</s> 10 new cases with input only.</li>
                  <li>Participants must submit verification reports and describe their methodology. Participants may also submit a scientific paper detailing their approach.</li>
                  <li>Submissions are evaluated, and <strong>only those who successfully pass the validation stage will qualify for the final competition</strong>.</li>
              </ul>
          </li>
      
          <li><strong>Stage 3 - Real-World Verification (July 28 - August 8)</strong>
              <ul>
                  <li>Only validated participants advance to this stage.</li>
                  <li>Organizers provide 10 real-time cases, reflecting ongoing misinformation challenges.</li>
                  <li>Participants verify cases, submit results, and optionally submit a camera-ready paper.</li>
              </ul>
          </li>
      </ul>
      <p> <em>Note:</em> To ensure the quality and accuracy of the cases, we have reduced the number of samples and only provide the high-quality ones.</p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop is-centered">
    <div class="content">
      <h2 class="title is-3">OOC Subtask: Out-of-Context Detection</h2>
      <h3 class="title is-4">Task Description</h3>

      <p>In this task, participants are asked to come up with methods to determine whether a given image-caption pair is genuine (real) or falsely generated (fake). More specifically, given an <code>&lt;Image, Caption&gt;</code> pair as input, their proposed model should predict corresponding class labels <code>0 (real)</code> or <code>1 (fake)</code>.</p>
  
      <p>We acknowledge that this is a challenging task without prior knowledge of the image origin, even for human moderators. In fact, <a href="https://aclanthology.org/2021.emnlp-main.545/">Luo et al.</a> have verified this challenge with a study on human evaluators, who were instructed not to use search engines, where the average human accuracy was only around <strong>65%</strong>.</p>
  
      <h2>Dataset</h2>
      <p>For this challenge, an augmented version of the COSMOS dataset will be used. A part of this dataset is sampled and assigned as the public dataset. The public dataset, consisting of the training, validation, and public test splits, is provided openly to participants for training and testing their algorithms. The remaining part of the COSMOS dataset is augmented with new samples and modified to create the hidden test split. The hidden test split is not made publicly available and will be used by the challenge organizers to evaluate the submissions.</p>
        <p>You can disregard caption2 for this task and focus only on caption1 from the public test set. In NOOC (Not-Out-of-Context) cases, caption1 forms a contextually accurate image-text pair. In contrast, in OOC (Out-of-Context) cases, caption1 is intentionally incorrect, resulting in an out-of-context image-text pair. The private test set will also have only 1 caption per image. Same as in the public test set.</p>

      <h3 class="title is-4">Challenge Dataset Statistics</h3>
        
      <table>
          <tr>
              <th>Dataset Split</th>
              <th>Number of Images</th>
              <th>Number of Captions</th>
              <th>Context Annotation</th>
          </tr>
          <tr>
              <td>Training</td>
              <td>161,752</td>
              <td>360,749</td>
              <td>No</td>
          </tr>
          <tr>
              <td>Validation</td>
              <td>41,006</td>
              <td>90,036</td>
              <td>No</td>
          </tr>
          <tr>
              <td>Public Test</td>
              <td>1,000</td>
              <td>2,000</td>
              <td>Yes</td>
          </tr>
          <tr>
              <td>Hidden Test</td>
              <td>1,000</td>
              <td>2,000</td>
              <td>Yes</td>
          </tr>
      </table>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop is-centered">
    <div class="content">
      <h2 class="title is-3">Resources</h2>
      <p>This section provides a list of useful resources for OSINT-based multimedia verification.</p>

      <h3 class="title is-4">Useful Links</h3>
      <ul>
        <li><a href="https://bellingcat.gitbook.io/toolkit">Bellingcat’s Online Open Source Investigation Toolkit</a></li>
        <li><a href="https://www.bellingcat.com/category/resources/">Bellingcat Guides</a></li>
        <li><a href="https://toolbox.google.com/factcheck">Google Fact Check Explorer</a></li>
        <li><a href="https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24970">Real-world Multimedia Verification Studies</a></li>
        <li><a href="https://ieeexplore.ieee.org/iel7/6287639/6514899/10017287.pdf">Visual User-Generated Content Verification in Journalism: An Overview</a></li>
        <li><a href="https://osintframework.com/">OSINT Framework</a></li>
        <li><a href="https://start.me/p/0Pqbdg/osint-500-tools">OSINT Tools and Resources</a></li>
		<li><a href="http://fotoverifier.eu:9000/home">FotoVerifier: Image Verification Tool</a></li>
        <li><a href="https://www.ntnu.no/ojs/index.php/nikt/article/view/6254/5591"> (Tool access upon request) VeriDash: An AI-Driven, User-Centric Open Source Dashboard for Enhancing Multimedia Verification</a></li>
      </ul>

      <h3 class="title is-4">References</h3>
      <ul>
        <li>Dang-Nguyen, D.T., Khan, S.A., Riegler, M., Halvorsen, P., Tran, A.D., Dao, M.S. and Tran, M.T., 2024, May. Overview of the Grand Challenge on Detecting Cheapfakes at ACM ICMR 2024. In Proceedings of the 2024 International Conference on Multimedia Retrieval (pp. 1275-1281).</li>
        <li>Khan, S.A., Dierickx, L., Furuly, J.G., Vold, H.B., Tahseen, R., Linden, C.G. and Dang‐Nguyen, D.T., 2024. Debunking war information disorder: A case study in assessing the use of multimedia verification tools. Journal of the Association for Information Science and Technology.</li>
        <li>Khan, S.A., Sheikhi, G., Opdahl, A.L., Rabbi, F., Stoppel, S., Trattner, C. and Dang-Nguyen, D.T., 2023. Visual user-generated content verification in journalism: An overview. IEEE Access, 11, pp.6748-6769.</li>
        <li>Boididou, C., Middleton, S.E., Jin, Z., Papadopoulos, S., Dang-Nguyen, D.T., Boato, G. and Kompatsiaris, Y., 2018. Verifying information with multimedia content on Twitter: a comparative study of automated approaches. Multimedia Tools and Applications, 77, pp.15545-15571.</li>
        <li>Boididou, C., Andreadou, K., Papadopoulos, S., Dang Nguyen, D.T., Boato, G., Riegler, M. and Kompatsiaris, Y., 2015. Verifying multimedia use at MediaEval 2015. In MediaEval 2015 (Vol. 1436). CEUR-WS.</li>
      </ul>
    </div>
  </div>
</section>


  
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-left">
      <p>Borrowed from <a href="https://github.com/nerfies/nerfies.github.io">source code</a></p>
    </div>
  </div>
</footer>

</body>
</html>
